{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycaret[tuners]\n",
      "  Using cached pycaret-3.3.2-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: ipython>=5.5.0 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from pycaret[tuners]) (8.26.0)\n",
      "Collecting ipywidgets>=7.6.5 (from pycaret[tuners])\n",
      "  Using cached ipywidgets-8.1.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: tqdm>=4.62.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pycaret[tuners]) (4.66.4)\n",
      "Collecting numpy<1.27,>=1.21 (from pycaret[tuners])\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "     ---------------------------------------- 0.0/61.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 61.0/61.0 kB 1.6 MB/s eta 0:00:00\n",
      "Collecting pandas<2.2.0 (from pycaret[tuners])\n",
      "  Downloading pandas-2.1.4-cp311-cp311-win_amd64.whl.metadata (18 kB)\n",
      "Requirement already satisfied: jinja2>=3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pycaret[tuners]) (3.1.4)\n",
      "Collecting scipy<=1.11.4,>=1.6.1 (from pycaret[tuners])\n",
      "  Downloading scipy-1.11.4-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "     ---------------------------------------- 0.0/60.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 60.4/60.4 kB ? eta 0:00:00\n",
      "Collecting joblib<1.4,>=1.2.0 (from pycaret[tuners])\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting scikit-learn>1.4.0 (from pycaret[tuners])\n",
      "  Downloading scikit_learn-1.5.1-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting pyod>=1.1.3 (from pycaret[tuners])\n",
      "  Using cached pyod-2.0.1-py3-none-any.whl\n",
      "Collecting imbalanced-learn>=0.12.0 (from pycaret[tuners])\n",
      "  Using cached imbalanced_learn-0.12.3-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting category-encoders>=2.4.0 (from pycaret[tuners])\n",
      "  Using cached category_encoders-2.6.3-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting lightgbm>=3.0.0 (from pycaret[tuners])\n",
      "  Using cached lightgbm-4.4.0-py3-none-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numba>=0.55.0 (from pycaret[tuners])\n",
      "  Downloading numba-0.60.0-cp311-cp311-win_amd64.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: requests>=2.27.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pycaret[tuners]) (2.32.3)\n",
      "Requirement already satisfied: psutil>=5.9.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pycaret[tuners]) (6.0.0)\n",
      "Requirement already satisfied: markupsafe>=2.0.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pycaret[tuners]) (2.1.5)\n",
      "Requirement already satisfied: importlib-metadata>=4.12.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pycaret[tuners]) (7.1.0)\n",
      "Collecting nbformat>=4.2.0 (from pycaret[tuners])\n",
      "  Using cached nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting cloudpickle (from pycaret[tuners])\n",
      "  Using cached cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting deprecation>=2.1.0 (from pycaret[tuners])\n",
      "  Using cached deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting xxhash (from pycaret[tuners])\n",
      "  Using cached xxhash-3.4.1-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting matplotlib<3.8.0 (from pycaret[tuners])\n",
      "  Using cached matplotlib-3.7.5-cp311-cp311-win_amd64.whl.metadata (5.8 kB)\n",
      "Collecting scikit-plot>=0.3.7 (from pycaret[tuners])\n",
      "  Using cached scikit_plot-0.3.7-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting yellowbrick>=1.4 (from pycaret[tuners])\n",
      "  Using cached yellowbrick-1.5-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting plotly>=5.14.0 (from pycaret[tuners])\n",
      "  Using cached plotly-5.22.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting kaleido>=0.2.1 (from pycaret[tuners])\n",
      "  Using cached kaleido-0.2.1-py2.py3-none-win_amd64.whl.metadata (15 kB)\n",
      "Collecting schemdraw==0.15 (from pycaret[tuners])\n",
      "  Using cached schemdraw-0.15-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting plotly-resampler>=0.8.3.1 (from pycaret[tuners])\n",
      "  Using cached plotly_resampler-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting statsmodels>=0.12.1 (from pycaret[tuners])\n",
      "  Downloading statsmodels-0.14.2-cp311-cp311-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting sktime==0.26.0 (from pycaret[tuners])\n",
      "  Using cached sktime-0.26.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting tbats>=1.1.3 (from pycaret[tuners])\n",
      "  Using cached tbats-1.1.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting pmdarima>=2.0.4 (from pycaret[tuners])\n",
      "  Using cached pmdarima-2.0.4-cp311-cp311-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting hyperopt>=0.2.7 (from pycaret[tuners])\n",
      "  Using cached hyperopt-0.2.7-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting optuna>=3.0.0 (from pycaret[tuners])\n",
      "  Using cached optuna-3.6.1-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting optuna-integration (from pycaret[tuners])\n",
      "  Using cached optuna_integration-3.6.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting scikit-optimize>=0.9.0 (from pycaret[tuners])\n",
      "  Using cached scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sktime==0.26.0->pycaret[tuners]) (24.1)\n",
      "Collecting scikit-base<0.8.0 (from sktime==0.26.0->pycaret[tuners])\n",
      "  Using cached scikit_base-0.7.8-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting scikit-learn>1.4.0 (from pycaret[tuners])\n",
      "  Using cached scikit_learn-1.4.2-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Collecting patsy>=0.5.1 (from category-encoders>=2.4.0->pycaret[tuners])\n",
      "  Using cached patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: six in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from hyperopt>=0.2.7->pycaret[tuners]) (1.16.0)\n",
      "Collecting networkx>=2.2 (from hyperopt>=0.2.7->pycaret[tuners])\n",
      "  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting future (from hyperopt>=0.2.7->pycaret[tuners])\n",
      "  Using cached future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting py4j (from hyperopt>=0.2.7->pycaret[tuners])\n",
      "  Using cached py4j-0.10.9.7-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from imbalanced-learn>=0.12.0->pycaret[tuners])\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from importlib-metadata>=4.12.0->pycaret[tuners]) (3.19.2)\n",
      "Requirement already satisfied: decorator in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=5.5.0->pycaret[tuners]) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=5.5.0->pycaret[tuners]) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=5.5.0->pycaret[tuners]) (0.1.7)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=5.5.0->pycaret[tuners]) (3.0.47)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=5.5.0->pycaret[tuners]) (2.18.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=5.5.0->pycaret[tuners]) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from ipython>=5.5.0->pycaret[tuners]) (5.14.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=5.5.0->pycaret[tuners]) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython>=5.5.0->pycaret[tuners]) (0.4.6)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from ipywidgets>=7.6.5->pycaret[tuners]) (0.2.2)\n",
      "Collecting widgetsnbextension~=4.0.11 (from ipywidgets>=7.6.5->pycaret[tuners])\n",
      "  Using cached widgetsnbextension-4.0.11-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.11 (from ipywidgets>=7.6.5->pycaret[tuners])\n",
      "  Using cached jupyterlab_widgets-3.0.11-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib<3.8.0->pycaret[tuners])\n",
      "  Downloading contourpy-1.2.1-cp311-cp311-win_amd64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib<3.8.0->pycaret[tuners])\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib<3.8.0->pycaret[tuners])\n",
      "  Downloading fonttools-4.53.1-cp311-cp311-win_amd64.whl.metadata (165 kB)\n",
      "     ---------------------------------------- 0.0/165.9 kB ? eta -:--:--\n",
      "     ------------------------------------  163.8/165.9 kB 10.2 MB/s eta 0:00:01\n",
      "     -------------------------------------- 165.9/165.9 kB 3.3 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.0.1 (from matplotlib<3.8.0->pycaret[tuners])\n",
      "  Downloading kiwisolver-1.4.5-cp311-cp311-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<3.8.0->pycaret[tuners]) (10.4.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib<3.8.0->pycaret[tuners])\n",
      "  Using cached pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib<3.8.0->pycaret[tuners]) (2.9.0.post0)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat>=4.2.0->pycaret[tuners])\n",
      "  Using cached fastjsonschema-2.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbformat>=4.2.0->pycaret[tuners]) (4.22.0)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from nbformat>=4.2.0->pycaret[tuners]) (5.7.2)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba>=0.55.0->pycaret[tuners])\n",
      "  Downloading llvmlite-0.43.0-cp311-cp311-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optuna>=3.0.0->pycaret[tuners]) (1.13.2)\n",
      "Requirement already satisfied: colorlog in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optuna>=3.0.0->pycaret[tuners]) (4.8.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optuna>=3.0.0->pycaret[tuners]) (1.4.52)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from optuna>=3.0.0->pycaret[tuners]) (6.0.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<2.2.0->pycaret[tuners]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas<2.2.0->pycaret[tuners]) (2024.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from plotly>=5.14.0->pycaret[tuners]) (8.5.0)\n",
      "Collecting dash>=2.9.0 (from plotly-resampler>=0.8.3.1->pycaret[tuners])\n",
      "  Using cached dash-2.17.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting orjson<4.0.0,>=3.8.0 (from plotly-resampler>=0.8.3.1->pycaret[tuners])\n",
      "  Downloading orjson-3.10.6-cp311-none-win_amd64.whl.metadata (51 kB)\n",
      "     ---------------------------------------- 0.0/51.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 51.6/51.6 kB 2.6 MB/s eta 0:00:00\n",
      "Collecting tsdownsample>=0.1.3 (from plotly-resampler>=0.8.3.1->pycaret[tuners])\n",
      "  Using cached tsdownsample-0.1.3-cp311-none-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting Cython!=0.29.18,!=0.29.31,>=0.29 (from pmdarima>=2.0.4->pycaret[tuners])\n",
      "  Using cached Cython-3.0.10-cp311-cp311-win_amd64.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pmdarima>=2.0.4->pycaret[tuners]) (2.2.2)\n",
      "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pmdarima>=2.0.4->pycaret[tuners]) (70.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.27.1->pycaret[tuners]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.27.1->pycaret[tuners]) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests>=2.27.1->pycaret[tuners]) (2024.7.4)\n",
      "Collecting pyaml>=16.9 (from scikit-optimize>=0.9.0->pycaret[tuners])\n",
      "  Using cached pyaml-24.4.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: Mako in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from alembic>=1.5.0->optuna>=3.0.0->pycaret[tuners]) (1.3.5)\n",
      "Requirement already satisfied: Flask<3.1,>=1.0.4 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret[tuners]) (2.2.5)\n",
      "Requirement already satisfied: Werkzeug<3.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret[tuners]) (2.2.3)\n",
      "Collecting dash-html-components==2.0.0 (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret[tuners])\n",
      "  Using cached dash_html_components-2.0.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting dash-core-components==2.0.0 (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret[tuners])\n",
      "  Using cached dash_core_components-2.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting dash-table==5.0.0 (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret[tuners])\n",
      "  Using cached dash_table-5.0.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting retrying (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret[tuners])\n",
      "  Using cached retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret[tuners]) (1.6.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from jedi>=0.16->ipython>=5.5.0->pycaret[tuners]) (0.8.4)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret[tuners]) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret[tuners]) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret[tuners]) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.6->nbformat>=4.2.0->pycaret[tuners]) (0.18.1)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=4.2.0->pycaret[tuners]) (4.2.2)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=4.2.0->pycaret[tuners]) (306)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=5.5.0->pycaret[tuners]) (0.2.13)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna>=3.0.0->pycaret[tuners]) (3.0.3)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=5.5.0->pycaret[tuners]) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=5.5.0->pycaret[tuners]) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\dell\\appdata\\roaming\\python\\python311\\site-packages (from stack-data->ipython>=5.5.0->pycaret[tuners]) (0.2.2)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret[tuners]) (2.2.0)\n",
      "Requirement already satisfied: click>=8.0 in c:\\users\\dell\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Flask<3.1,>=1.0.4->dash>=2.9.0->plotly-resampler>=0.8.3.1->pycaret[tuners]) (8.1.7)\n",
      "Using cached schemdraw-0.15-py3-none-any.whl (106 kB)\n",
      "Using cached sktime-0.26.0-py3-none-any.whl (21.8 MB)\n",
      "Using cached category_encoders-2.6.3-py2.py3-none-any.whl (81 kB)\n",
      "Using cached deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached hyperopt-0.2.7-py2.py3-none-any.whl (1.6 MB)\n",
      "Using cached imbalanced_learn-0.12.3-py3-none-any.whl (258 kB)\n",
      "Using cached ipywidgets-8.1.3-py3-none-any.whl (139 kB)\n",
      "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Using cached kaleido-0.2.1-py2.py3-none-win_amd64.whl (65.9 MB)\n",
      "Using cached lightgbm-4.4.0-py3-none-win_amd64.whl (1.4 MB)\n",
      "Using cached matplotlib-3.7.5-cp311-cp311-win_amd64.whl (7.5 MB)\n",
      "Using cached nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Downloading numba-0.60.0-cp311-cp311-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 1.0/2.7 MB 20.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 2.1/2.7 MB 21.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.7/2.7 MB 21.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 17.2 MB/s eta 0:00:00\n",
      "Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.7/15.8 MB 21.1 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 1.5/15.8 MB 18.5 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 2.5/15.8 MB 17.6 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 2.6/15.8 MB 16.6 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 3.0/15.8 MB 12.0 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.8/15.8 MB 16.1 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 6.6/15.8 MB 19.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 7.6/15.8 MB 18.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 9.3/15.8 MB 20.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 10.5/15.8 MB 21.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 12.3/15.8 MB 24.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.1/15.8 MB 29.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.1/15.8 MB 29.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.5/15.8 MB 25.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 25.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 25.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.8/15.8 MB 25.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 18.2 MB/s eta 0:00:00\n",
      "Using cached optuna-3.6.1-py3-none-any.whl (380 kB)\n",
      "Downloading pandas-2.1.4-cp311-cp311-win_amd64.whl (10.6 MB)\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.9/10.6 MB 19.6 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 2.1/10.6 MB 22.1 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 2.4/10.6 MB 17.2 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.1/10.6 MB 18.2 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.1/10.6 MB 18.2 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.1/10.6 MB 18.2 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.1/10.6 MB 18.2 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.8/10.6 MB 10.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.2/10.6 MB 12.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.7/10.6 MB 11.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.1/10.6 MB 11.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.2/10.6 MB 11.6 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.3/10.6 MB 10.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.5/10.6 MB 9.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.3/10.6 MB 10.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.3/10.6 MB 10.2 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.3/10.6 MB 10.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.4/10.6 MB 8.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.2/10.6 MB 8.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.6/10.6 MB 8.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.1/10.6 MB 8.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.8/10.6 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.5/10.6 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.6/10.6 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.6/10.6 MB 8.7 MB/s eta 0:00:00\n",
      "Using cached plotly-5.22.0-py3-none-any.whl (16.4 MB)\n",
      "Using cached plotly_resampler-0.10.0-py3-none-any.whl (80 kB)\n",
      "Using cached pmdarima-2.0.4-cp311-cp311-win_amd64.whl (614 kB)\n",
      "Using cached scikit_learn-1.4.2-cp311-cp311-win_amd64.whl (10.6 MB)\n",
      "Using cached scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
      "Using cached scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
      "Downloading scipy-1.11.4-cp311-cp311-win_amd64.whl (44.1 MB)\n",
      "   ---------------------------------------- 0.0/44.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.8/44.1 MB 26.8 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 1.2/44.1 MB 12.9 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 1.8/44.1 MB 14.7 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 2.1/44.1 MB 12.1 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 2.1/44.1 MB 12.1 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 2.1/44.1 MB 12.1 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 2.1/44.1 MB 12.1 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 2.1/44.1 MB 12.1 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 2.1/44.1 MB 12.1 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 2.1/44.1 MB 12.1 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 2.7/44.1 MB 5.2 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 3.1/44.1 MB 5.4 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 3.1/44.1 MB 5.4 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 3.2/44.1 MB 4.7 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 4.2/44.1 MB 5.6 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 4.8/44.1 MB 5.9 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 5.4/44.1 MB 6.2 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 5.4/44.1 MB 6.2 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 5.9/44.1 MB 6.1 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 6.3/44.1 MB 6.3 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 6.3/44.1 MB 6.3 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 6.3/44.1 MB 6.3 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 6.3/44.1 MB 6.3 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 6.3/44.1 MB 6.3 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 6.5/44.1 MB 5.2 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 6.8/44.1 MB 5.2 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 7.1/44.1 MB 5.2 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 7.4/44.1 MB 5.2 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 7.8/44.1 MB 5.3 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 8.1/44.1 MB 5.3 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 8.4/44.1 MB 5.4 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 8.6/44.1 MB 5.4 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 8.9/44.1 MB 5.5 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 9.3/44.1 MB 5.5 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 9.7/44.1 MB 5.6 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 10.0/44.1 MB 5.7 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 10.3/44.1 MB 5.6 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 10.8/44.1 MB 5.5 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 11.1/44.1 MB 5.5 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 11.5/44.1 MB 5.5 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 11.5/44.1 MB 5.5 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 11.6/44.1 MB 5.2 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 12.2/44.1 MB 5.2 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 12.6/44.1 MB 6.1 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 13.3/44.1 MB 6.1 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 13.7/44.1 MB 6.5 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 14.1/44.1 MB 6.4 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 14.6/44.1 MB 6.3 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 14.7/44.1 MB 6.2 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 14.7/44.1 MB 6.2 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 14.7/44.1 MB 6.2 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 14.9/44.1 MB 5.6 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 15.4/44.1 MB 5.6 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 15.7/44.1 MB 5.8 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 15.7/44.1 MB 5.8 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 15.7/44.1 MB 5.8 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 16.1/44.1 MB 5.4 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 16.5/44.1 MB 5.4 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 16.8/44.1 MB 6.1 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 17.2/44.1 MB 6.1 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 17.6/44.1 MB 6.2 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 17.9/44.1 MB 6.2 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 18.3/44.1 MB 6.1 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 18.7/44.1 MB 6.2 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 19.0/44.1 MB 6.2 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 19.2/44.1 MB 6.1 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 19.5/44.1 MB 6.0 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 19.8/44.1 MB 6.0 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 20.1/44.1 MB 5.8 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 20.3/44.1 MB 5.8 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 20.7/44.1 MB 5.8 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 20.9/44.1 MB 5.6 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 21.2/44.1 MB 5.6 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 21.4/44.1 MB 5.6 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 21.7/44.1 MB 5.5 MB/s eta 0:00:05\n",
      "   ------------------- -------------------- 21.9/44.1 MB 5.7 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 22.1/44.1 MB 5.7 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 22.4/44.1 MB 5.6 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 22.8/44.1 MB 5.6 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 23.1/44.1 MB 5.5 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 23.4/44.1 MB 5.4 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 23.7/44.1 MB 5.4 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 24.0/44.1 MB 5.3 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 24.4/44.1 MB 5.3 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 24.5/44.1 MB 5.2 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 24.8/44.1 MB 5.2 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 25.2/44.1 MB 5.6 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 25.6/44.1 MB 5.5 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 25.8/44.1 MB 5.4 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 26.2/44.1 MB 5.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 26.6/44.1 MB 5.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 27.0/44.1 MB 5.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 27.3/44.1 MB 5.6 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 27.7/44.1 MB 5.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 28.0/44.1 MB 5.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 28.3/44.1 MB 5.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 28.7/44.1 MB 5.8 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 29.1/44.1 MB 5.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 29.5/44.1 MB 5.8 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 29.9/44.1 MB 5.8 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 30.2/44.1 MB 5.9 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 30.6/44.1 MB 6.1 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 30.9/44.1 MB 6.0 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 31.3/44.1 MB 6.2 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 31.7/44.1 MB 6.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 32.0/44.1 MB 6.4 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 32.4/44.1 MB 6.5 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 33.0/44.1 MB 6.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 33.5/44.1 MB 6.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 33.8/44.1 MB 6.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 34.2/44.1 MB 7.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 34.6/44.1 MB 7.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 35.1/44.1 MB 7.3 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 35.4/44.1 MB 7.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 36.0/44.1 MB 7.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 36.1/44.1 MB 7.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 36.5/44.1 MB 7.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 37.0/44.1 MB 7.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 37.3/44.1 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 37.5/44.1 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 37.9/44.1 MB 7.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 38.1/44.1 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 38.5/44.1 MB 7.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 38.8/44.1 MB 7.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 39.0/44.1 MB 7.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 39.4/44.1 MB 7.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 39.6/44.1 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 40.0/44.1 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 40.2/44.1 MB 7.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 40.5/44.1 MB 7.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 40.8/44.1 MB 7.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 41.1/44.1 MB 7.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 41.4/44.1 MB 7.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 41.6/44.1 MB 7.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 41.9/44.1 MB 6.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 42.3/44.1 MB 6.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 42.6/44.1 MB 6.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 42.8/44.1 MB 6.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 42.8/44.1 MB 6.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 42.8/44.1 MB 6.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.0/44.1 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.2/44.1 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.3/44.1 MB 6.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.6/44.1 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  43.9/44.1 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.1 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.1 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.1 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.1 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.1/44.1 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.1/44.1 MB 5.2 MB/s eta 0:00:00\n",
      "Downloading statsmodels-0.14.2-cp311-cp311-win_amd64.whl (9.9 MB)\n",
      "   ---------------------------------------- 0.0/9.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.4/9.9 MB 8.3 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.6/9.9 MB 7.1 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 0.9/9.9 MB 5.6 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 1.1/9.9 MB 5.9 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.4/9.9 MB 5.7 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.7/9.9 MB 5.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.1/9.9 MB 5.7 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.2/9.9 MB 5.7 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.5/9.9 MB 5.7 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 3.8/9.9 MB 5.9 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.1/9.9 MB 5.9 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 4.3/9.9 MB 5.9 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.6/9.9 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 4.9/9.9 MB 5.9 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.2/9.9 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.5/9.9 MB 6.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 5.8/9.9 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.1/9.9 MB 5.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.5/9.9 MB 5.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.8/9.9 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.0/9.9 MB 5.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.4/9.9 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.6/9.9 MB 5.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 7.9/9.9 MB 5.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 8.2/9.9 MB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.6/9.9 MB 5.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.0/9.9 MB 5.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.4/9.9 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.7/9.9 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.7/9.9 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.7/9.9 MB 5.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.7/9.9 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.9/9.9 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.9/9.9 MB 5.2 MB/s eta 0:00:00\n",
      "Using cached tbats-1.1.3-py3-none-any.whl (44 kB)\n",
      "Using cached yellowbrick-1.5-py3-none-any.whl (282 kB)\n",
      "Using cached cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Using cached optuna_integration-3.6.0-py3-none-any.whl (93 kB)\n",
      "Using cached pycaret-3.3.2-py3-none-any.whl (486 kB)\n",
      "Using cached xxhash-3.4.1-cp311-cp311-win_amd64.whl (29 kB)\n",
      "Downloading contourpy-1.2.1-cp311-cp311-win_amd64.whl (188 kB)\n",
      "   ---------------------------------------- 0.0/188.2 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 92.2/188.2 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 188.2/188.2 kB 1.9 MB/s eta 0:00:00\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Using cached Cython-3.0.10-cp311-cp311-win_amd64.whl (2.8 MB)\n",
      "Using cached dash-2.17.1-py3-none-any.whl (7.5 MB)\n",
      "Using cached dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n",
      "Using cached dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n",
      "Using cached dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n",
      "Using cached fastjsonschema-2.20.0-py3-none-any.whl (23 kB)\n",
      "Downloading fonttools-4.53.1-cp311-cp311-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.2/2.2 MB 3.7 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.5/2.2 MB 5.3 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.8/2.2 MB 5.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 1.2/2.2 MB 5.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 1.5/2.2 MB 5.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.8/2.2 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.2/2.2 MB 5.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 5.0 MB/s eta 0:00:00\n",
      "Using cached jupyterlab_widgets-3.0.11-py3-none-any.whl (214 kB)\n",
      "Downloading kiwisolver-1.4.5-cp311-cp311-win_amd64.whl (56 kB)\n",
      "   ---------------------------------------- 0.0/56.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 56.1/56.1 kB 3.1 MB/s eta 0:00:00\n",
      "Downloading llvmlite-0.43.0-cp311-cp311-win_amd64.whl (28.1 MB)\n",
      "   ---------------------------------------- 0.0/28.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/28.1 MB 8.6 MB/s eta 0:00:04\n",
      "    --------------------------------------- 0.5/28.1 MB 5.0 MB/s eta 0:00:06\n",
      "    --------------------------------------- 0.7/28.1 MB 4.7 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.9/28.1 MB 5.4 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 1.2/28.1 MB 5.2 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 1.5/28.1 MB 5.4 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 1.8/28.1 MB 5.4 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 2.0/28.1 MB 5.7 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 2.1/28.1 MB 5.5 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 2.1/28.1 MB 5.5 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 2.1/28.1 MB 5.5 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 2.1/28.1 MB 5.5 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 2.1/28.1 MB 5.5 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 2.2/28.1 MB 3.5 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 2.4/28.1 MB 3.4 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 2.4/28.1 MB 3.4 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 2.4/28.1 MB 3.4 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 2.4/28.1 MB 3.4 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 2.5/28.1 MB 2.8 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 2.6/28.1 MB 2.8 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 2.6/28.1 MB 2.8 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 2.6/28.1 MB 2.8 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 2.6/28.1 MB 2.8 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 2.7/28.1 MB 2.4 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 2.7/28.1 MB 2.4 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 2.7/28.1 MB 2.4 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 2.7/28.1 MB 2.4 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 2.8/28.1 MB 2.1 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 2.8/28.1 MB 2.0 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 2.8/28.1 MB 2.0 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 2.8/28.1 MB 2.0 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 2.8/28.1 MB 2.0 MB/s eta 0:00:13\n",
      "   ---- ----------------------------------- 2.9/28.1 MB 1.9 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 2.9/28.1 MB 1.8 MB/s eta 0:00:14\n",
      "   ---- ----------------------------------- 2.9/28.1 MB 1.8 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 3.0/28.1 MB 1.8 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 3.1/28.1 MB 1.7 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 3.2/28.1 MB 1.7 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 3.3/28.1 MB 1.7 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 3.3/28.1 MB 1.7 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 3.5/28.1 MB 1.7 MB/s eta 0:00:15\n",
      "   ---- ----------------------------------- 3.5/28.1 MB 1.7 MB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 3.6/28.1 MB 1.7 MB/s eta 0:00:15\n",
      "   ----- ---------------------------------- 3.7/28.1 MB 1.8 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 3.7/28.1 MB 1.7 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 3.9/28.1 MB 1.8 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 4.0/28.1 MB 1.8 MB/s eta 0:00:14\n",
      "   ----- ---------------------------------- 4.1/28.1 MB 1.8 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 4.2/28.1 MB 1.8 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 4.4/28.1 MB 1.8 MB/s eta 0:00:14\n",
      "   ------ --------------------------------- 4.5/28.1 MB 1.8 MB/s eta 0:00:13\n",
      "   ------ --------------------------------- 4.6/28.1 MB 1.8 MB/s eta 0:00:13\n",
      "   ------ --------------------------------- 4.8/28.1 MB 1.9 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 4.9/28.1 MB 1.9 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 5.1/28.1 MB 1.9 MB/s eta 0:00:13\n",
      "   ------- -------------------------------- 5.3/28.1 MB 1.9 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 5.4/28.1 MB 1.9 MB/s eta 0:00:12\n",
      "   ------- -------------------------------- 5.5/28.1 MB 2.0 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 5.7/28.1 MB 2.0 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 5.9/28.1 MB 2.0 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 6.0/28.1 MB 2.0 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 6.1/28.1 MB 2.0 MB/s eta 0:00:12\n",
      "   -------- ------------------------------- 6.2/28.1 MB 2.0 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 6.3/28.1 MB 2.0 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 6.5/28.1 MB 2.0 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 6.6/28.1 MB 2.0 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 6.7/28.1 MB 2.0 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 6.9/28.1 MB 2.1 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 7.0/28.1 MB 2.1 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 7.2/28.1 MB 2.1 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 7.4/28.1 MB 2.1 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 7.4/28.1 MB 2.1 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 7.4/28.1 MB 2.1 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 7.4/28.1 MB 2.1 MB/s eta 0:00:10\n",
      "   ---------- ----------------------------- 7.4/28.1 MB 2.0 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 7.5/28.1 MB 2.0 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 7.5/28.1 MB 2.0 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 7.6/28.1 MB 2.0 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 7.7/28.1 MB 2.0 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 7.8/28.1 MB 2.0 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 7.8/28.1 MB 2.0 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 8.0/28.1 MB 2.0 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 8.0/28.1 MB 2.0 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 8.2/28.1 MB 2.0 MB/s eta 0:00:10\n",
      "   ----------- ---------------------------- 8.3/28.1 MB 2.0 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 8.4/28.1 MB 2.0 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 8.6/28.1 MB 2.0 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 8.7/28.1 MB 2.1 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 8.8/28.1 MB 2.1 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 8.9/28.1 MB 2.1 MB/s eta 0:00:10\n",
      "   ------------ --------------------------- 9.0/28.1 MB 2.1 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 9.2/28.1 MB 2.1 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 9.3/28.1 MB 2.1 MB/s eta 0:00:10\n",
      "   ------------- -------------------------- 9.4/28.1 MB 2.1 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 9.6/28.1 MB 2.1 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 9.7/28.1 MB 2.1 MB/s eta 0:00:09\n",
      "   ------------- -------------------------- 9.8/28.1 MB 2.1 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 10.0/28.1 MB 2.1 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 10.1/28.1 MB 2.1 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 10.3/28.1 MB 2.1 MB/s eta 0:00:09\n",
      "   -------------- ------------------------- 10.4/28.1 MB 2.1 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 10.6/28.1 MB 2.1 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 10.8/28.1 MB 2.1 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 11.0/28.1 MB 2.1 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 11.0/28.1 MB 2.1 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 11.2/28.1 MB 2.1 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 11.4/28.1 MB 2.1 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 11.5/28.1 MB 2.1 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 11.7/28.1 MB 2.1 MB/s eta 0:00:08\n",
      "   ---------------- ----------------------- 11.9/28.1 MB 2.1 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 12.1/28.1 MB 2.1 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 12.3/28.1 MB 2.1 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 12.5/28.1 MB 2.2 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 12.7/28.1 MB 2.2 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 13.0/28.1 MB 2.4 MB/s eta 0:00:07\n",
      "   ------------------ --------------------- 13.1/28.1 MB 2.6 MB/s eta 0:00:06\n",
      "   ------------------ --------------------- 13.3/28.1 MB 2.7 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 13.5/28.1 MB 2.7 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 13.6/28.1 MB 2.8 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 13.8/28.1 MB 2.8 MB/s eta 0:00:06\n",
      "   ------------------- -------------------- 13.9/28.1 MB 2.8 MB/s eta 0:00:06\n",
      "   -------------------- ------------------- 14.1/28.1 MB 2.8 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 14.3/28.1 MB 2.9 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 14.5/28.1 MB 2.9 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 14.6/28.1 MB 2.9 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 14.7/28.1 MB 2.9 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 14.9/28.1 MB 2.9 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 15.2/28.1 MB 3.0 MB/s eta 0:00:05\n",
      "   --------------------- ------------------ 15.4/28.1 MB 3.0 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 15.6/28.1 MB 3.0 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 15.8/28.1 MB 3.0 MB/s eta 0:00:05\n",
      "   ---------------------- ----------------- 16.1/28.1 MB 3.1 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 16.4/28.1 MB 3.1 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 16.7/28.1 MB 3.2 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 16.7/28.1 MB 3.2 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 16.7/28.1 MB 3.2 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 16.7/28.1 MB 3.2 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 16.8/28.1 MB 3.0 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 16.8/28.1 MB 3.0 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 16.9/28.1 MB 3.0 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 17.0/28.1 MB 3.0 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 17.2/28.1 MB 3.0 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 17.4/28.1 MB 3.0 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 17.6/28.1 MB 3.0 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 17.8/28.1 MB 3.3 MB/s eta 0:00:04\n",
      "   ------------------------- -------------- 18.1/28.1 MB 3.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------- 18.3/28.1 MB 3.4 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 18.5/28.1 MB 3.4 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 18.7/28.1 MB 3.5 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 18.9/28.1 MB 3.5 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 19.1/28.1 MB 3.5 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 19.3/28.1 MB 3.6 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 19.5/28.1 MB 3.6 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 19.7/28.1 MB 3.6 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 19.9/28.1 MB 3.6 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 20.1/28.1 MB 3.7 MB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 20.3/28.1 MB 3.7 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 20.5/28.1 MB 3.7 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 20.7/28.1 MB 3.7 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 21.0/28.1 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 21.3/28.1 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 21.6/28.1 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 21.7/28.1 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 21.9/28.1 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 22.2/28.1 MB 3.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 22.6/28.1 MB 3.9 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 22.8/28.1 MB 3.9 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 23.0/28.1 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 23.3/28.1 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 23.6/28.1 MB 3.9 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 23.9/28.1 MB 4.0 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 24.2/28.1 MB 4.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 24.4/28.1 MB 4.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 24.7/28.1 MB 4.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 25.0/28.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 25.3/28.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 25.5/28.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 25.8/28.1 MB 4.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 26.3/28.1 MB 4.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 26.7/28.1 MB 4.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 27.0/28.1 MB 4.6 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 27.3/28.1 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  27.6/28.1 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  28.0/28.1 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  28.1/28.1 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  28.1/28.1 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  28.1/28.1 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  28.1/28.1 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  28.1/28.1 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 28.1/28.1 MB 4.4 MB/s eta 0:00:00\n",
      "Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Downloading orjson-3.10.6-cp311-none-win_amd64.whl (136 kB)\n",
      "   ---------------------------------------- 0.0/136.4 kB ? eta -:--:--\n",
      "   ---------------------------------------  133.1/136.4 kB 8.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 136.4/136.4 kB 2.7 MB/s eta 0:00:00\n",
      "Using cached patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "Using cached pyaml-24.4.0-py3-none-any.whl (24 kB)\n",
      "Using cached pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "Using cached scikit_base-0.7.8-py3-none-any.whl (130 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached tsdownsample-0.1.3-cp311-none-win_amd64.whl (923 kB)\n",
      "Using cached widgetsnbextension-4.0.11-py3-none-any.whl (2.3 MB)\n",
      "Using cached future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Using cached py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "Using cached retrying-1.3.4-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: py4j, kaleido, fastjsonschema, dash-table, dash-html-components, dash-core-components, xxhash, widgetsnbextension, threadpoolctl, scikit-base, schemdraw, retrying, pyparsing, pyaml, plotly, orjson, numpy, networkx, llvmlite, kiwisolver, jupyterlab-widgets, joblib, future, fonttools, deprecation, Cython, cycler, cloudpickle, tsdownsample, scipy, patsy, pandas, numba, contourpy, statsmodels, scikit-learn, optuna, matplotlib, lightgbm, hyperopt, dash, yellowbrick, sktime, scikit-plot, scikit-optimize, pyod, pmdarima, plotly-resampler, optuna-integration, nbformat, ipywidgets, imbalanced-learn, category-encoders, tbats, pycaret\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.0\n",
      "    Uninstalling numpy-2.0.0:\n",
      "      Successfully uninstalled numpy-2.0.0\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.2\n",
      "    Uninstalling pandas-2.2.2:\n",
      "      Successfully uninstalled pandas-2.2.2\n",
      "Successfully installed Cython-3.0.10 category-encoders-2.6.3 cloudpickle-3.0.0 contourpy-1.2.1 cycler-0.12.1 dash-2.17.1 dash-core-components-2.0.0 dash-html-components-2.0.0 dash-table-5.0.0 deprecation-2.1.0 fastjsonschema-2.20.0 fonttools-4.53.1 future-1.0.0 hyperopt-0.2.7 imbalanced-learn-0.12.3 ipywidgets-8.1.3 joblib-1.3.2 jupyterlab-widgets-3.0.11 kaleido-0.2.1 kiwisolver-1.4.5 lightgbm-4.4.0 llvmlite-0.43.0 matplotlib-3.7.5 nbformat-5.10.4 networkx-3.3 numba-0.60.0 numpy-1.26.4 optuna-3.6.1 optuna-integration-3.6.0 orjson-3.10.6 pandas-2.1.4 patsy-0.5.6 plotly-5.22.0 plotly-resampler-0.10.0 pmdarima-2.0.4 py4j-0.10.9.7 pyaml-24.4.0 pycaret-3.3.2 pyod-2.0.1 pyparsing-3.1.2 retrying-1.3.4 schemdraw-0.15 scikit-base-0.7.8 scikit-learn-1.4.2 scikit-optimize-0.10.2 scikit-plot-0.3.7 scipy-1.11.4 sktime-0.26.0 statsmodels-0.14.2 tbats-1.1.3 threadpoolctl-3.5.0 tsdownsample-0.1.3 widgetsnbextension-4.0.11 xxhash-3.4.1 yellowbrick-1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install pycaret[tuners]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Marital status</th>\n",
       "      <th>Application mode</th>\n",
       "      <th>Application order</th>\n",
       "      <th>Course</th>\n",
       "      <th>Daytime/evening attendance</th>\n",
       "      <th>Previous qualification</th>\n",
       "      <th>Previous qualification (grade)</th>\n",
       "      <th>Nacionality</th>\n",
       "      <th>Mother's qualification</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 2nd sem (credited)</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>12.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>9238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>9254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>12.820000</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "      <td>Enrolled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>12.933333</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76513</th>\n",
       "      <td>76513</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>9254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>121.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76514</th>\n",
       "      <td>76514</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>9254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>13.875000</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76515</th>\n",
       "      <td>76515</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>9085</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>138.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>9.4</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>Enrolled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76516</th>\n",
       "      <td>76516</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9070</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>136.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76517</th>\n",
       "      <td>76517</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>133.1</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-4.06</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76518 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  Marital status  Application mode  Application order  Course  \\\n",
       "0          0               1                 1                  1    9238   \n",
       "1          1               1                17                  1    9238   \n",
       "2          2               1                17                  2    9254   \n",
       "3          3               1                 1                  3    9500   \n",
       "4          4               1                 1                  2    9500   \n",
       "...      ...             ...               ...                ...     ...   \n",
       "76513  76513               1                17                  1    9254   \n",
       "76514  76514               1                 1                  6    9254   \n",
       "76515  76515               5                17                  1    9085   \n",
       "76516  76516               1                 1                  3    9070   \n",
       "76517  76517               1                 1                  1    9773   \n",
       "\n",
       "       Daytime/evening attendance  Previous qualification  \\\n",
       "0                               1                       1   \n",
       "1                               1                       1   \n",
       "2                               1                       1   \n",
       "3                               1                       1   \n",
       "4                               1                       1   \n",
       "...                           ...                     ...   \n",
       "76513                           1                       1   \n",
       "76514                           1                       1   \n",
       "76515                           1                       1   \n",
       "76516                           1                       1   \n",
       "76517                           1                       1   \n",
       "\n",
       "       Previous qualification (grade)  Nacionality  Mother's qualification  \\\n",
       "0                               126.0            1                       1   \n",
       "1                               125.0            1                      19   \n",
       "2                               137.0            1                       3   \n",
       "3                               131.0            1                      19   \n",
       "4                               132.0            1                      19   \n",
       "...                               ...          ...                     ...   \n",
       "76513                           121.0            1                      19   \n",
       "76514                           125.0            1                       1   \n",
       "76515                           138.0            1                      37   \n",
       "76516                           136.0            1                      38   \n",
       "76517                           133.1            1                      19   \n",
       "\n",
       "       ...  Curricular units 2nd sem (credited)  \\\n",
       "0      ...                                    0   \n",
       "1      ...                                    0   \n",
       "2      ...                                    0   \n",
       "3      ...                                    0   \n",
       "4      ...                                    0   \n",
       "...    ...                                  ...   \n",
       "76513  ...                                    0   \n",
       "76514  ...                                    0   \n",
       "76515  ...                                    0   \n",
       "76516  ...                                    0   \n",
       "76517  ...                                    0   \n",
       "\n",
       "       Curricular units 2nd sem (enrolled)  \\\n",
       "0                                        6   \n",
       "1                                        6   \n",
       "2                                        6   \n",
       "3                                        8   \n",
       "4                                        7   \n",
       "...                                    ...   \n",
       "76513                                    6   \n",
       "76514                                    6   \n",
       "76515                                    5   \n",
       "76516                                    6   \n",
       "76517                                    6   \n",
       "\n",
       "       Curricular units 2nd sem (evaluations)  \\\n",
       "0                                           7   \n",
       "1                                           9   \n",
       "2                                           0   \n",
       "3                                          11   \n",
       "4                                          12   \n",
       "...                                       ...   \n",
       "76513                                       8   \n",
       "76514                                       9   \n",
       "76515                                       8   \n",
       "76516                                       0   \n",
       "76517                                       6   \n",
       "\n",
       "       Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "0                                        6                         12.428571   \n",
       "1                                        0                          0.000000   \n",
       "2                                        0                          0.000000   \n",
       "3                                        7                         12.820000   \n",
       "4                                        6                         12.933333   \n",
       "...                                    ...                               ...   \n",
       "76513                                    5                         10.600000   \n",
       "76514                                    6                         13.875000   \n",
       "76515                                    5                         11.400000   \n",
       "76516                                    0                          0.000000   \n",
       "76517                                    6                         13.666667   \n",
       "\n",
       "       Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "0                                                   0               11.1   \n",
       "1                                                   0               11.1   \n",
       "2                                                   0               16.2   \n",
       "3                                                   0               11.1   \n",
       "4                                                   0                7.6   \n",
       "...                                               ...                ...   \n",
       "76513                                               0               13.9   \n",
       "76514                                               0                9.4   \n",
       "76515                                               1                9.4   \n",
       "76516                                               0                7.6   \n",
       "76517                                               0               15.5   \n",
       "\n",
       "       Inflation rate   GDP    Target  \n",
       "0                 0.6  2.02  Graduate  \n",
       "1                 0.6  2.02   Dropout  \n",
       "2                 0.3 -0.92   Dropout  \n",
       "3                 0.6  2.02  Enrolled  \n",
       "4                 2.6  0.32  Graduate  \n",
       "...               ...   ...       ...  \n",
       "76513            -0.3  0.79  Graduate  \n",
       "76514            -0.8 -3.12  Graduate  \n",
       "76515            -0.8 -3.12  Enrolled  \n",
       "76516             2.6  0.32   Dropout  \n",
       "76517             2.8 -4.06  Graduate  \n",
       "\n",
       "[76518 rows x 38 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('train.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                                  int64\n",
      "Marital status                                      int64\n",
      "Application mode                                    int64\n",
      "Application order                                   int64\n",
      "Course                                              int64\n",
      "Daytime/evening attendance                          int64\n",
      "Previous qualification                              int64\n",
      "Previous qualification (grade)                    float64\n",
      "Nacionality                                         int64\n",
      "Mother's qualification                              int64\n",
      "Father's qualification                              int64\n",
      "Mother's occupation                                 int64\n",
      "Father's occupation                                 int64\n",
      "Admission grade                                   float64\n",
      "Displaced                                           int64\n",
      "Educational special needs                           int64\n",
      "Debtor                                              int64\n",
      "Tuition fees up to date                             int64\n",
      "Gender                                              int64\n",
      "Scholarship holder                                  int64\n",
      "Age at enrollment                                   int64\n",
      "International                                       int64\n",
      "Curricular units 1st sem (credited)                 int64\n",
      "Curricular units 1st sem (enrolled)                 int64\n",
      "Curricular units 1st sem (evaluations)              int64\n",
      "Curricular units 1st sem (approved)                 int64\n",
      "Curricular units 1st sem (grade)                  float64\n",
      "Curricular units 1st sem (without evaluations)      int64\n",
      "Curricular units 2nd sem (credited)                 int64\n",
      "Curricular units 2nd sem (enrolled)                 int64\n",
      "Curricular units 2nd sem (evaluations)              int64\n",
      "Curricular units 2nd sem (approved)                 int64\n",
      "Curricular units 2nd sem (grade)                  float64\n",
      "Curricular units 2nd sem (without evaluations)      int64\n",
      "Unemployment rate                                 float64\n",
      "Inflation rate                                    float64\n",
      "GDP                                               float64\n",
      "Target                                             object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "column_types = df.dtypes\n",
    "\n",
    "print(column_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Marital status</th>\n",
       "      <th>Application mode</th>\n",
       "      <th>Application order</th>\n",
       "      <th>Course</th>\n",
       "      <th>Daytime/evening attendance</th>\n",
       "      <th>Previous qualification</th>\n",
       "      <th>Previous qualification (grade)</th>\n",
       "      <th>Nacionality</th>\n",
       "      <th>Mother's qualification</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 2nd sem (credited)</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>126.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>12.428571</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>9238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>125.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>9254</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>16.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>Dropout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>12.820000</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "      <td>Enrolled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>9500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132.0</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>12.933333</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Marital status  Application mode  Application order  Course  \\\n",
       "0   0               1                 1                  1    9238   \n",
       "1   1               1                17                  1    9238   \n",
       "2   2               1                17                  2    9254   \n",
       "3   3               1                 1                  3    9500   \n",
       "4   4               1                 1                  2    9500   \n",
       "\n",
       "   Daytime/evening attendance  Previous qualification  \\\n",
       "0                           1                       1   \n",
       "1                           1                       1   \n",
       "2                           1                       1   \n",
       "3                           1                       1   \n",
       "4                           1                       1   \n",
       "\n",
       "   Previous qualification (grade)  Nacionality  Mother's qualification  ...  \\\n",
       "0                           126.0            1                       1  ...   \n",
       "1                           125.0            1                      19  ...   \n",
       "2                           137.0            1                       3  ...   \n",
       "3                           131.0            1                      19  ...   \n",
       "4                           132.0            1                      19  ...   \n",
       "\n",
       "   Curricular units 2nd sem (credited)  Curricular units 2nd sem (enrolled)  \\\n",
       "0                                    0                                    6   \n",
       "1                                    0                                    6   \n",
       "2                                    0                                    6   \n",
       "3                                    0                                    8   \n",
       "4                                    0                                    7   \n",
       "\n",
       "   Curricular units 2nd sem (evaluations)  \\\n",
       "0                                       7   \n",
       "1                                       9   \n",
       "2                                       0   \n",
       "3                                      11   \n",
       "4                                      12   \n",
       "\n",
       "   Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "0                                    6                         12.428571   \n",
       "1                                    0                          0.000000   \n",
       "2                                    0                          0.000000   \n",
       "3                                    7                         12.820000   \n",
       "4                                    6                         12.933333   \n",
       "\n",
       "   Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "0                                               0               11.1   \n",
       "1                                               0               11.1   \n",
       "2                                               0               16.2   \n",
       "3                                               0               11.1   \n",
       "4                                               0                7.6   \n",
       "\n",
       "   Inflation rate   GDP    Target  \n",
       "0             0.6  2.02  Graduate  \n",
       "1             0.6  2.02   Dropout  \n",
       "2             0.3 -0.92   Dropout  \n",
       "3             0.6  2.02  Enrolled  \n",
       "4             2.6  0.32  Graduate  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_87d4c_row10_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_87d4c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_87d4c_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_87d4c_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_87d4c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_87d4c_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_87d4c_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87d4c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_87d4c_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_87d4c_row1_col1\" class=\"data row1 col1\" >Target</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87d4c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_87d4c_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_87d4c_row2_col1\" class=\"data row2 col1\" >Multiclass</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87d4c_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_87d4c_row3_col0\" class=\"data row3 col0\" >Target mapping</td>\n",
       "      <td id=\"T_87d4c_row3_col1\" class=\"data row3 col1\" >Dropout: 0, Enrolled: 1, Graduate: 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87d4c_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_87d4c_row4_col0\" class=\"data row4 col0\" >Original data shape</td>\n",
       "      <td id=\"T_87d4c_row4_col1\" class=\"data row4 col1\" >(76518, 38)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87d4c_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_87d4c_row5_col0\" class=\"data row5 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_87d4c_row5_col1\" class=\"data row5 col1\" >(76518, 37)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87d4c_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_87d4c_row6_col0\" class=\"data row6 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_87d4c_row6_col1\" class=\"data row6 col1\" >(53562, 37)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87d4c_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_87d4c_row7_col0\" class=\"data row7 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_87d4c_row7_col1\" class=\"data row7 col1\" >(22956, 37)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87d4c_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_87d4c_row8_col0\" class=\"data row8 col0\" >Ignore features</td>\n",
       "      <td id=\"T_87d4c_row8_col1\" class=\"data row8 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87d4c_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_87d4c_row9_col0\" class=\"data row9 col0\" >Numeric features</td>\n",
       "      <td id=\"T_87d4c_row9_col1\" class=\"data row9 col1\" >36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87d4c_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_87d4c_row10_col0\" class=\"data row10 col0\" >Preprocess</td>\n",
       "      <td id=\"T_87d4c_row10_col1\" class=\"data row10 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87d4c_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_87d4c_row11_col0\" class=\"data row11 col0\" >Imputation type</td>\n",
       "      <td id=\"T_87d4c_row11_col1\" class=\"data row11 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87d4c_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_87d4c_row12_col0\" class=\"data row12 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_87d4c_row12_col1\" class=\"data row12 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87d4c_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_87d4c_row13_col0\" class=\"data row13 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_87d4c_row13_col1\" class=\"data row13 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87d4c_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_87d4c_row14_col0\" class=\"data row14 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_87d4c_row14_col1\" class=\"data row14 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87d4c_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_87d4c_row15_col0\" class=\"data row15 col0\" >Fold Number</td>\n",
       "      <td id=\"T_87d4c_row15_col1\" class=\"data row15 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87d4c_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_87d4c_row16_col0\" class=\"data row16 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_87d4c_row16_col1\" class=\"data row16 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87d4c_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_87d4c_row17_col0\" class=\"data row17 col0\" >Use GPU</td>\n",
       "      <td id=\"T_87d4c_row17_col1\" class=\"data row17 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87d4c_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_87d4c_row18_col0\" class=\"data row18 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_87d4c_row18_col1\" class=\"data row18 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87d4c_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_87d4c_row19_col0\" class=\"data row19 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_87d4c_row19_col1\" class=\"data row19 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_87d4c_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_87d4c_row20_col0\" class=\"data row20 col0\" >USI</td>\n",
       "      <td id=\"T_87d4c_row20_col1\" class=\"data row20 col1\" >4bcc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1d6d039c910>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from pycaret.classification import setup, compare_models, create_model, tune_model, plot_model, evaluate_model, finalize_model, predict_model, save_model, load_model\n",
    "\n",
    "# Load your dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Configuración del experimento\n",
    "exp_sc180897 = setup(data=df, \n",
    "                   target='Target', \n",
    "                   session_id=123, \n",
    "                   train_size=0.7, \n",
    "                   ignore_features=['id'], \n",
    "                   numeric_features=[\"Marital status\",\"Application mode\",\"Application order\",\"Course\",\"Daytime/evening attendance\",\"Previous qualification\",\"Previous qualification (grade)\",\"Nacionality\",\"Mother's qualification\",\"Father's qualification\",\"Mother's occupation\",\"Father's occupation\",\"Admission grade\",\"Displaced\",\"Educational special needs\",\"Debtor\",\"Tuition fees up to date\",\"Gender\",\"Scholarship holder\",\"Age at enrollment\",\"International\",\"Curricular units 1st sem (credited)\",\"Curricular units 1st sem (enrolled)\",\"Curricular units 1st sem (evaluations)\",\"Curricular units 1st sem (approved)\",\"Curricular units 1st sem (grade)\",\"Curricular units 1st sem (without evaluations)\",\"Curricular units 2nd sem (credited)\",\"Curricular units 2nd sem (enrolled)\",\"Curricular units 2nd sem (evaluations)\",\"Curricular units 2nd sem (approved)\",\"Curricular units 2nd sem (grade)\",\"Curricular units 2nd sem (without evaluations)\",\"Unemployment rate\",\"Inflation rate\",\"GDP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_4b0ab th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_4b0ab_row0_col0, #T_4b0ab_row1_col0, #T_4b0ab_row1_col1, #T_4b0ab_row1_col2, #T_4b0ab_row1_col3, #T_4b0ab_row1_col4, #T_4b0ab_row1_col5, #T_4b0ab_row1_col6, #T_4b0ab_row1_col7, #T_4b0ab_row2_col0, #T_4b0ab_row2_col1, #T_4b0ab_row2_col2, #T_4b0ab_row2_col3, #T_4b0ab_row2_col4, #T_4b0ab_row2_col5, #T_4b0ab_row2_col6, #T_4b0ab_row2_col7, #T_4b0ab_row3_col0, #T_4b0ab_row3_col1, #T_4b0ab_row3_col2, #T_4b0ab_row3_col3, #T_4b0ab_row3_col4, #T_4b0ab_row3_col5, #T_4b0ab_row3_col6, #T_4b0ab_row3_col7, #T_4b0ab_row4_col0, #T_4b0ab_row4_col1, #T_4b0ab_row4_col2, #T_4b0ab_row4_col3, #T_4b0ab_row4_col4, #T_4b0ab_row4_col5, #T_4b0ab_row4_col6, #T_4b0ab_row4_col7, #T_4b0ab_row5_col0, #T_4b0ab_row5_col1, #T_4b0ab_row5_col2, #T_4b0ab_row5_col3, #T_4b0ab_row5_col4, #T_4b0ab_row5_col5, #T_4b0ab_row5_col6, #T_4b0ab_row5_col7, #T_4b0ab_row6_col0, #T_4b0ab_row6_col1, #T_4b0ab_row6_col2, #T_4b0ab_row6_col3, #T_4b0ab_row6_col4, #T_4b0ab_row6_col5, #T_4b0ab_row6_col6, #T_4b0ab_row6_col7, #T_4b0ab_row7_col0, #T_4b0ab_row7_col1, #T_4b0ab_row7_col2, #T_4b0ab_row7_col3, #T_4b0ab_row7_col4, #T_4b0ab_row7_col5, #T_4b0ab_row7_col6, #T_4b0ab_row7_col7, #T_4b0ab_row8_col0, #T_4b0ab_row8_col1, #T_4b0ab_row8_col2, #T_4b0ab_row8_col3, #T_4b0ab_row8_col4, #T_4b0ab_row8_col5, #T_4b0ab_row8_col6, #T_4b0ab_row8_col7, #T_4b0ab_row9_col0, #T_4b0ab_row9_col1, #T_4b0ab_row9_col2, #T_4b0ab_row9_col3, #T_4b0ab_row9_col4, #T_4b0ab_row9_col5, #T_4b0ab_row9_col6, #T_4b0ab_row9_col7, #T_4b0ab_row10_col0, #T_4b0ab_row10_col1, #T_4b0ab_row10_col2, #T_4b0ab_row10_col3, #T_4b0ab_row10_col4, #T_4b0ab_row10_col5, #T_4b0ab_row10_col6, #T_4b0ab_row10_col7, #T_4b0ab_row11_col0, #T_4b0ab_row11_col1, #T_4b0ab_row11_col2, #T_4b0ab_row11_col3, #T_4b0ab_row11_col4, #T_4b0ab_row11_col5, #T_4b0ab_row11_col6, #T_4b0ab_row11_col7, #T_4b0ab_row12_col0, #T_4b0ab_row12_col1, #T_4b0ab_row12_col2, #T_4b0ab_row12_col3, #T_4b0ab_row12_col4, #T_4b0ab_row12_col5, #T_4b0ab_row12_col6, #T_4b0ab_row12_col7, #T_4b0ab_row13_col0, #T_4b0ab_row13_col1, #T_4b0ab_row13_col2, #T_4b0ab_row13_col3, #T_4b0ab_row13_col4, #T_4b0ab_row13_col5, #T_4b0ab_row13_col6, #T_4b0ab_row13_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_4b0ab_row0_col1, #T_4b0ab_row0_col2, #T_4b0ab_row0_col3, #T_4b0ab_row0_col4, #T_4b0ab_row0_col5, #T_4b0ab_row0_col6, #T_4b0ab_row0_col7 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_4b0ab_row0_col8, #T_4b0ab_row1_col8, #T_4b0ab_row2_col8, #T_4b0ab_row3_col8, #T_4b0ab_row4_col8, #T_4b0ab_row5_col8, #T_4b0ab_row6_col8, #T_4b0ab_row7_col8, #T_4b0ab_row8_col8, #T_4b0ab_row9_col8, #T_4b0ab_row10_col8, #T_4b0ab_row11_col8, #T_4b0ab_row12_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_4b0ab_row13_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_4b0ab\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_4b0ab_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_4b0ab_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_4b0ab_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_4b0ab_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_4b0ab_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_4b0ab_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_4b0ab_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_4b0ab_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_4b0ab_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_4b0ab_level0_row0\" class=\"row_heading level0 row0\" >lightgbm</th>\n",
       "      <td id=\"T_4b0ab_row0_col0\" class=\"data row0 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_4b0ab_row0_col1\" class=\"data row0 col1\" >0.8293</td>\n",
       "      <td id=\"T_4b0ab_row0_col2\" class=\"data row0 col2\" >0.9432</td>\n",
       "      <td id=\"T_4b0ab_row0_col3\" class=\"data row0 col3\" >0.8293</td>\n",
       "      <td id=\"T_4b0ab_row0_col4\" class=\"data row0 col4\" >0.8288</td>\n",
       "      <td id=\"T_4b0ab_row0_col5\" class=\"data row0 col5\" >0.8278</td>\n",
       "      <td id=\"T_4b0ab_row0_col6\" class=\"data row0 col6\" >0.7251</td>\n",
       "      <td id=\"T_4b0ab_row0_col7\" class=\"data row0 col7\" >0.7265</td>\n",
       "      <td id=\"T_4b0ab_row0_col8\" class=\"data row0 col8\" >2.4880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b0ab_level0_row1\" class=\"row_heading level0 row1\" >gbc</th>\n",
       "      <td id=\"T_4b0ab_row1_col0\" class=\"data row1 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_4b0ab_row1_col1\" class=\"data row1 col1\" >0.8267</td>\n",
       "      <td id=\"T_4b0ab_row1_col2\" class=\"data row1 col2\" >0.0000</td>\n",
       "      <td id=\"T_4b0ab_row1_col3\" class=\"data row1 col3\" >0.8267</td>\n",
       "      <td id=\"T_4b0ab_row1_col4\" class=\"data row1 col4\" >0.8259</td>\n",
       "      <td id=\"T_4b0ab_row1_col5\" class=\"data row1 col5\" >0.8249</td>\n",
       "      <td id=\"T_4b0ab_row1_col6\" class=\"data row1 col6\" >0.7207</td>\n",
       "      <td id=\"T_4b0ab_row1_col7\" class=\"data row1 col7\" >0.7223</td>\n",
       "      <td id=\"T_4b0ab_row1_col8\" class=\"data row1 col8\" >12.7930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b0ab_level0_row2\" class=\"row_heading level0 row2\" >rf</th>\n",
       "      <td id=\"T_4b0ab_row2_col0\" class=\"data row2 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_4b0ab_row2_col1\" class=\"data row2 col1\" >0.8248</td>\n",
       "      <td id=\"T_4b0ab_row2_col2\" class=\"data row2 col2\" >0.9378</td>\n",
       "      <td id=\"T_4b0ab_row2_col3\" class=\"data row2 col3\" >0.8248</td>\n",
       "      <td id=\"T_4b0ab_row2_col4\" class=\"data row2 col4\" >0.8235</td>\n",
       "      <td id=\"T_4b0ab_row2_col5\" class=\"data row2 col5\" >0.8227</td>\n",
       "      <td id=\"T_4b0ab_row2_col6\" class=\"data row2 col6\" >0.7174</td>\n",
       "      <td id=\"T_4b0ab_row2_col7\" class=\"data row2 col7\" >0.7191</td>\n",
       "      <td id=\"T_4b0ab_row2_col8\" class=\"data row2 col8\" >3.9050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b0ab_level0_row3\" class=\"row_heading level0 row3\" >et</th>\n",
       "      <td id=\"T_4b0ab_row3_col0\" class=\"data row3 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_4b0ab_row3_col1\" class=\"data row3 col1\" >0.8230</td>\n",
       "      <td id=\"T_4b0ab_row3_col2\" class=\"data row3 col2\" >0.9363</td>\n",
       "      <td id=\"T_4b0ab_row3_col3\" class=\"data row3 col3\" >0.8230</td>\n",
       "      <td id=\"T_4b0ab_row3_col4\" class=\"data row3 col4\" >0.8218</td>\n",
       "      <td id=\"T_4b0ab_row3_col5\" class=\"data row3 col5\" >0.8206</td>\n",
       "      <td id=\"T_4b0ab_row3_col6\" class=\"data row3 col6\" >0.7141</td>\n",
       "      <td id=\"T_4b0ab_row3_col7\" class=\"data row3 col7\" >0.7161</td>\n",
       "      <td id=\"T_4b0ab_row3_col8\" class=\"data row3 col8\" >3.9600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b0ab_level0_row4\" class=\"row_heading level0 row4\" >ada</th>\n",
       "      <td id=\"T_4b0ab_row4_col0\" class=\"data row4 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_4b0ab_row4_col1\" class=\"data row4 col1\" >0.8186</td>\n",
       "      <td id=\"T_4b0ab_row4_col2\" class=\"data row4 col2\" >0.0000</td>\n",
       "      <td id=\"T_4b0ab_row4_col3\" class=\"data row4 col3\" >0.8186</td>\n",
       "      <td id=\"T_4b0ab_row4_col4\" class=\"data row4 col4\" >0.8192</td>\n",
       "      <td id=\"T_4b0ab_row4_col5\" class=\"data row4 col5\" >0.8172</td>\n",
       "      <td id=\"T_4b0ab_row4_col6\" class=\"data row4 col6\" >0.7078</td>\n",
       "      <td id=\"T_4b0ab_row4_col7\" class=\"data row4 col7\" >0.7097</td>\n",
       "      <td id=\"T_4b0ab_row4_col8\" class=\"data row4 col8\" >1.4600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b0ab_level0_row5\" class=\"row_heading level0 row5\" >lda</th>\n",
       "      <td id=\"T_4b0ab_row5_col0\" class=\"data row5 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_4b0ab_row5_col1\" class=\"data row5 col1\" >0.8042</td>\n",
       "      <td id=\"T_4b0ab_row5_col2\" class=\"data row5 col2\" >0.0000</td>\n",
       "      <td id=\"T_4b0ab_row5_col3\" class=\"data row5 col3\" >0.8042</td>\n",
       "      <td id=\"T_4b0ab_row5_col4\" class=\"data row5 col4\" >0.8089</td>\n",
       "      <td id=\"T_4b0ab_row5_col5\" class=\"data row5 col5\" >0.8023</td>\n",
       "      <td id=\"T_4b0ab_row5_col6\" class=\"data row5 col6\" >0.6830</td>\n",
       "      <td id=\"T_4b0ab_row5_col7\" class=\"data row5 col7\" >0.6873</td>\n",
       "      <td id=\"T_4b0ab_row5_col8\" class=\"data row5 col8\" >0.3520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b0ab_level0_row6\" class=\"row_heading level0 row6\" >ridge</th>\n",
       "      <td id=\"T_4b0ab_row6_col0\" class=\"data row6 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_4b0ab_row6_col1\" class=\"data row6 col1\" >0.7934</td>\n",
       "      <td id=\"T_4b0ab_row6_col2\" class=\"data row6 col2\" >0.0000</td>\n",
       "      <td id=\"T_4b0ab_row6_col3\" class=\"data row6 col3\" >0.7934</td>\n",
       "      <td id=\"T_4b0ab_row6_col4\" class=\"data row6 col4\" >0.7891</td>\n",
       "      <td id=\"T_4b0ab_row6_col5\" class=\"data row6 col5\" >0.7799</td>\n",
       "      <td id=\"T_4b0ab_row6_col6\" class=\"data row6 col6\" >0.6565</td>\n",
       "      <td id=\"T_4b0ab_row6_col7\" class=\"data row6 col7\" >0.6691</td>\n",
       "      <td id=\"T_4b0ab_row6_col8\" class=\"data row6 col8\" >0.2150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b0ab_level0_row7\" class=\"row_heading level0 row7\" >lr</th>\n",
       "      <td id=\"T_4b0ab_row7_col0\" class=\"data row7 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_4b0ab_row7_col1\" class=\"data row7 col1\" >0.7888</td>\n",
       "      <td id=\"T_4b0ab_row7_col2\" class=\"data row7 col2\" >0.0000</td>\n",
       "      <td id=\"T_4b0ab_row7_col3\" class=\"data row7 col3\" >0.7888</td>\n",
       "      <td id=\"T_4b0ab_row7_col4\" class=\"data row7 col4\" >0.7876</td>\n",
       "      <td id=\"T_4b0ab_row7_col5\" class=\"data row7 col5\" >0.7850</td>\n",
       "      <td id=\"T_4b0ab_row7_col6\" class=\"data row7 col6\" >0.6575</td>\n",
       "      <td id=\"T_4b0ab_row7_col7\" class=\"data row7 col7\" >0.6610</td>\n",
       "      <td id=\"T_4b0ab_row7_col8\" class=\"data row7 col8\" >8.5950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b0ab_level0_row8\" class=\"row_heading level0 row8\" >qda</th>\n",
       "      <td id=\"T_4b0ab_row8_col0\" class=\"data row8 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_4b0ab_row8_col1\" class=\"data row8 col1\" >0.7713</td>\n",
       "      <td id=\"T_4b0ab_row8_col2\" class=\"data row8 col2\" >0.0000</td>\n",
       "      <td id=\"T_4b0ab_row8_col3\" class=\"data row8 col3\" >0.7713</td>\n",
       "      <td id=\"T_4b0ab_row8_col4\" class=\"data row8 col4\" >0.7618</td>\n",
       "      <td id=\"T_4b0ab_row8_col5\" class=\"data row8 col5\" >0.7642</td>\n",
       "      <td id=\"T_4b0ab_row8_col6\" class=\"data row8 col6\" >0.6283</td>\n",
       "      <td id=\"T_4b0ab_row8_col7\" class=\"data row8 col7\" >0.6307</td>\n",
       "      <td id=\"T_4b0ab_row8_col8\" class=\"data row8 col8\" >0.3480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b0ab_level0_row9\" class=\"row_heading level0 row9\" >nb</th>\n",
       "      <td id=\"T_4b0ab_row9_col0\" class=\"data row9 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_4b0ab_row9_col1\" class=\"data row9 col1\" >0.7661</td>\n",
       "      <td id=\"T_4b0ab_row9_col2\" class=\"data row9 col2\" >0.8912</td>\n",
       "      <td id=\"T_4b0ab_row9_col3\" class=\"data row9 col3\" >0.7661</td>\n",
       "      <td id=\"T_4b0ab_row9_col4\" class=\"data row9 col4\" >0.7599</td>\n",
       "      <td id=\"T_4b0ab_row9_col5\" class=\"data row9 col5\" >0.7603</td>\n",
       "      <td id=\"T_4b0ab_row9_col6\" class=\"data row9 col6\" >0.6195</td>\n",
       "      <td id=\"T_4b0ab_row9_col7\" class=\"data row9 col7\" >0.6225</td>\n",
       "      <td id=\"T_4b0ab_row9_col8\" class=\"data row9 col8\" >0.1970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b0ab_level0_row10\" class=\"row_heading level0 row10\" >dt</th>\n",
       "      <td id=\"T_4b0ab_row10_col0\" class=\"data row10 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_4b0ab_row10_col1\" class=\"data row10 col1\" >0.7404</td>\n",
       "      <td id=\"T_4b0ab_row10_col2\" class=\"data row10 col2\" >0.8030</td>\n",
       "      <td id=\"T_4b0ab_row10_col3\" class=\"data row10 col3\" >0.7404</td>\n",
       "      <td id=\"T_4b0ab_row10_col4\" class=\"data row10 col4\" >0.7435</td>\n",
       "      <td id=\"T_4b0ab_row10_col5\" class=\"data row10 col5\" >0.7418</td>\n",
       "      <td id=\"T_4b0ab_row10_col6\" class=\"data row10 col6\" >0.5882</td>\n",
       "      <td id=\"T_4b0ab_row10_col7\" class=\"data row10 col7\" >0.5883</td>\n",
       "      <td id=\"T_4b0ab_row10_col8\" class=\"data row10 col8\" >0.4960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b0ab_level0_row11\" class=\"row_heading level0 row11\" >knn</th>\n",
       "      <td id=\"T_4b0ab_row11_col0\" class=\"data row11 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_4b0ab_row11_col1\" class=\"data row11 col1\" >0.7280</td>\n",
       "      <td id=\"T_4b0ab_row11_col2\" class=\"data row11 col2\" >0.8534</td>\n",
       "      <td id=\"T_4b0ab_row11_col3\" class=\"data row11 col3\" >0.7280</td>\n",
       "      <td id=\"T_4b0ab_row11_col4\" class=\"data row11 col4\" >0.7224</td>\n",
       "      <td id=\"T_4b0ab_row11_col5\" class=\"data row11 col5\" >0.7241</td>\n",
       "      <td id=\"T_4b0ab_row11_col6\" class=\"data row11 col6\" >0.5608</td>\n",
       "      <td id=\"T_4b0ab_row11_col7\" class=\"data row11 col7\" >0.5620</td>\n",
       "      <td id=\"T_4b0ab_row11_col8\" class=\"data row11 col8\" >1.7930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b0ab_level0_row12\" class=\"row_heading level0 row12\" >svm</th>\n",
       "      <td id=\"T_4b0ab_row12_col0\" class=\"data row12 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_4b0ab_row12_col1\" class=\"data row12 col1\" >0.6086</td>\n",
       "      <td id=\"T_4b0ab_row12_col2\" class=\"data row12 col2\" >0.0000</td>\n",
       "      <td id=\"T_4b0ab_row12_col3\" class=\"data row12 col3\" >0.6086</td>\n",
       "      <td id=\"T_4b0ab_row12_col4\" class=\"data row12 col4\" >0.6917</td>\n",
       "      <td id=\"T_4b0ab_row12_col5\" class=\"data row12 col5\" >0.5587</td>\n",
       "      <td id=\"T_4b0ab_row12_col6\" class=\"data row12 col6\" >0.4138</td>\n",
       "      <td id=\"T_4b0ab_row12_col7\" class=\"data row12 col7\" >0.4710</td>\n",
       "      <td id=\"T_4b0ab_row12_col8\" class=\"data row12 col8\" >4.2090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_4b0ab_level0_row13\" class=\"row_heading level0 row13\" >dummy</th>\n",
       "      <td id=\"T_4b0ab_row13_col0\" class=\"data row13 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_4b0ab_row13_col1\" class=\"data row13 col1\" >0.4742</td>\n",
       "      <td id=\"T_4b0ab_row13_col2\" class=\"data row13 col2\" >0.5000</td>\n",
       "      <td id=\"T_4b0ab_row13_col3\" class=\"data row13 col3\" >0.4742</td>\n",
       "      <td id=\"T_4b0ab_row13_col4\" class=\"data row13 col4\" >0.2248</td>\n",
       "      <td id=\"T_4b0ab_row13_col5\" class=\"data row13 col5\" >0.3050</td>\n",
       "      <td id=\"T_4b0ab_row13_col6\" class=\"data row13 col6\" >0.0000</td>\n",
       "      <td id=\"T_4b0ab_row13_col7\" class=\"data row13 col7\" >0.0000</td>\n",
       "      <td id=\"T_4b0ab_row13_col8\" class=\"data row13 col8\" >0.1640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1d6d03a1810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Comparación de modelos\n",
    "best_model = compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_2c04c_row10_col0, #T_2c04c_row10_col1, #T_2c04c_row10_col2, #T_2c04c_row10_col3, #T_2c04c_row10_col4, #T_2c04c_row10_col5, #T_2c04c_row10_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_2c04c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_2c04c_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_2c04c_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_2c04c_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_2c04c_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_2c04c_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_2c04c_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_2c04c_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_2c04c_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_2c04c_row0_col0\" class=\"data row0 col0\" >0.8346</td>\n",
       "      <td id=\"T_2c04c_row0_col1\" class=\"data row0 col1\" >0.9461</td>\n",
       "      <td id=\"T_2c04c_row0_col2\" class=\"data row0 col2\" >0.8346</td>\n",
       "      <td id=\"T_2c04c_row0_col3\" class=\"data row0 col3\" >0.8345</td>\n",
       "      <td id=\"T_2c04c_row0_col4\" class=\"data row0 col4\" >0.8336</td>\n",
       "      <td id=\"T_2c04c_row0_col5\" class=\"data row0 col5\" >0.7344</td>\n",
       "      <td id=\"T_2c04c_row0_col6\" class=\"data row0 col6\" >0.7354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c04c_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_2c04c_row1_col0\" class=\"data row1 col0\" >0.8225</td>\n",
       "      <td id=\"T_2c04c_row1_col1\" class=\"data row1 col1\" >0.9418</td>\n",
       "      <td id=\"T_2c04c_row1_col2\" class=\"data row1 col2\" >0.8225</td>\n",
       "      <td id=\"T_2c04c_row1_col3\" class=\"data row1 col3\" >0.8214</td>\n",
       "      <td id=\"T_2c04c_row1_col4\" class=\"data row1 col4\" >0.8208</td>\n",
       "      <td id=\"T_2c04c_row1_col5\" class=\"data row1 col5\" >0.7142</td>\n",
       "      <td id=\"T_2c04c_row1_col6\" class=\"data row1 col6\" >0.7155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c04c_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_2c04c_row2_col0\" class=\"data row2 col0\" >0.8204</td>\n",
       "      <td id=\"T_2c04c_row2_col1\" class=\"data row2 col1\" >0.9384</td>\n",
       "      <td id=\"T_2c04c_row2_col2\" class=\"data row2 col2\" >0.8204</td>\n",
       "      <td id=\"T_2c04c_row2_col3\" class=\"data row2 col3\" >0.8199</td>\n",
       "      <td id=\"T_2c04c_row2_col4\" class=\"data row2 col4\" >0.8188</td>\n",
       "      <td id=\"T_2c04c_row2_col5\" class=\"data row2 col5\" >0.7106</td>\n",
       "      <td id=\"T_2c04c_row2_col6\" class=\"data row2 col6\" >0.7121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c04c_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_2c04c_row3_col0\" class=\"data row3 col0\" >0.8413</td>\n",
       "      <td id=\"T_2c04c_row3_col1\" class=\"data row3 col1\" >0.9484</td>\n",
       "      <td id=\"T_2c04c_row3_col2\" class=\"data row3 col2\" >0.8413</td>\n",
       "      <td id=\"T_2c04c_row3_col3\" class=\"data row3 col3\" >0.8418</td>\n",
       "      <td id=\"T_2c04c_row3_col4\" class=\"data row3 col4\" >0.8404</td>\n",
       "      <td id=\"T_2c04c_row3_col5\" class=\"data row3 col5\" >0.7448</td>\n",
       "      <td id=\"T_2c04c_row3_col6\" class=\"data row3 col6\" >0.7462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c04c_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_2c04c_row4_col0\" class=\"data row4 col0\" >0.8264</td>\n",
       "      <td id=\"T_2c04c_row4_col1\" class=\"data row4 col1\" >0.9437</td>\n",
       "      <td id=\"T_2c04c_row4_col2\" class=\"data row4 col2\" >0.8264</td>\n",
       "      <td id=\"T_2c04c_row4_col3\" class=\"data row4 col3\" >0.8261</td>\n",
       "      <td id=\"T_2c04c_row4_col4\" class=\"data row4 col4\" >0.8252</td>\n",
       "      <td id=\"T_2c04c_row4_col5\" class=\"data row4 col5\" >0.7207</td>\n",
       "      <td id=\"T_2c04c_row4_col6\" class=\"data row4 col6\" >0.7219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c04c_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_2c04c_row5_col0\" class=\"data row5 col0\" >0.8277</td>\n",
       "      <td id=\"T_2c04c_row5_col1\" class=\"data row5 col1\" >0.9409</td>\n",
       "      <td id=\"T_2c04c_row5_col2\" class=\"data row5 col2\" >0.8277</td>\n",
       "      <td id=\"T_2c04c_row5_col3\" class=\"data row5 col3\" >0.8244</td>\n",
       "      <td id=\"T_2c04c_row5_col4\" class=\"data row5 col4\" >0.8242</td>\n",
       "      <td id=\"T_2c04c_row5_col5\" class=\"data row5 col5\" >0.7212</td>\n",
       "      <td id=\"T_2c04c_row5_col6\" class=\"data row5 col6\" >0.7232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c04c_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_2c04c_row6_col0\" class=\"data row6 col0\" >0.8282</td>\n",
       "      <td id=\"T_2c04c_row6_col1\" class=\"data row6 col1\" >0.9437</td>\n",
       "      <td id=\"T_2c04c_row6_col2\" class=\"data row6 col2\" >0.8282</td>\n",
       "      <td id=\"T_2c04c_row6_col3\" class=\"data row6 col3\" >0.8284</td>\n",
       "      <td id=\"T_2c04c_row6_col4\" class=\"data row6 col4\" >0.8270</td>\n",
       "      <td id=\"T_2c04c_row6_col5\" class=\"data row6 col5\" >0.7235</td>\n",
       "      <td id=\"T_2c04c_row6_col6\" class=\"data row6 col6\" >0.7249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c04c_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_2c04c_row7_col0\" class=\"data row7 col0\" >0.8254</td>\n",
       "      <td id=\"T_2c04c_row7_col1\" class=\"data row7 col1\" >0.9418</td>\n",
       "      <td id=\"T_2c04c_row7_col2\" class=\"data row7 col2\" >0.8254</td>\n",
       "      <td id=\"T_2c04c_row7_col3\" class=\"data row7 col3\" >0.8256</td>\n",
       "      <td id=\"T_2c04c_row7_col4\" class=\"data row7 col4\" >0.8240</td>\n",
       "      <td id=\"T_2c04c_row7_col5\" class=\"data row7 col5\" >0.7188</td>\n",
       "      <td id=\"T_2c04c_row7_col6\" class=\"data row7 col6\" >0.7205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c04c_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_2c04c_row8_col0\" class=\"data row8 col0\" >0.8344</td>\n",
       "      <td id=\"T_2c04c_row8_col1\" class=\"data row8 col1\" >0.9420</td>\n",
       "      <td id=\"T_2c04c_row8_col2\" class=\"data row8 col2\" >0.8344</td>\n",
       "      <td id=\"T_2c04c_row8_col3\" class=\"data row8 col3\" >0.8331</td>\n",
       "      <td id=\"T_2c04c_row8_col4\" class=\"data row8 col4\" >0.8326</td>\n",
       "      <td id=\"T_2c04c_row8_col5\" class=\"data row8 col5\" >0.7332</td>\n",
       "      <td id=\"T_2c04c_row8_col6\" class=\"data row8 col6\" >0.7346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c04c_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_2c04c_row9_col0\" class=\"data row9 col0\" >0.8318</td>\n",
       "      <td id=\"T_2c04c_row9_col1\" class=\"data row9 col1\" >0.9451</td>\n",
       "      <td id=\"T_2c04c_row9_col2\" class=\"data row9 col2\" >0.8318</td>\n",
       "      <td id=\"T_2c04c_row9_col3\" class=\"data row9 col3\" >0.8328</td>\n",
       "      <td id=\"T_2c04c_row9_col4\" class=\"data row9 col4\" >0.8310</td>\n",
       "      <td id=\"T_2c04c_row9_col5\" class=\"data row9 col5\" >0.7296</td>\n",
       "      <td id=\"T_2c04c_row9_col6\" class=\"data row9 col6\" >0.7310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c04c_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_2c04c_row10_col0\" class=\"data row10 col0\" >0.8293</td>\n",
       "      <td id=\"T_2c04c_row10_col1\" class=\"data row10 col1\" >0.9432</td>\n",
       "      <td id=\"T_2c04c_row10_col2\" class=\"data row10 col2\" >0.8293</td>\n",
       "      <td id=\"T_2c04c_row10_col3\" class=\"data row10 col3\" >0.8288</td>\n",
       "      <td id=\"T_2c04c_row10_col4\" class=\"data row10 col4\" >0.8278</td>\n",
       "      <td id=\"T_2c04c_row10_col5\" class=\"data row10 col5\" >0.7251</td>\n",
       "      <td id=\"T_2c04c_row10_col6\" class=\"data row10 col6\" >0.7265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_2c04c_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_2c04c_row11_col0\" class=\"data row11 col0\" >0.0060</td>\n",
       "      <td id=\"T_2c04c_row11_col1\" class=\"data row11 col1\" >0.0027</td>\n",
       "      <td id=\"T_2c04c_row11_col2\" class=\"data row11 col2\" >0.0060</td>\n",
       "      <td id=\"T_2c04c_row11_col3\" class=\"data row11 col3\" >0.0064</td>\n",
       "      <td id=\"T_2c04c_row11_col4\" class=\"data row11 col4\" >0.0062</td>\n",
       "      <td id=\"T_2c04c_row11_col5\" class=\"data row11 col5\" >0.0098</td>\n",
       "      <td id=\"T_2c04c_row11_col6\" class=\"data row11 col6\" >0.0098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1d6d06ebb50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dt = create_model('lightgbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_710ed_row10_col0, #T_710ed_row10_col1, #T_710ed_row10_col2, #T_710ed_row10_col3, #T_710ed_row10_col4, #T_710ed_row10_col5, #T_710ed_row10_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_710ed\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_710ed_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_710ed_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_710ed_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_710ed_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_710ed_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_710ed_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_710ed_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_710ed_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_710ed_row0_col0\" class=\"data row0 col0\" >0.8361</td>\n",
       "      <td id=\"T_710ed_row0_col1\" class=\"data row0 col1\" >0.9466</td>\n",
       "      <td id=\"T_710ed_row0_col2\" class=\"data row0 col2\" >0.8361</td>\n",
       "      <td id=\"T_710ed_row0_col3\" class=\"data row0 col3\" >0.8359</td>\n",
       "      <td id=\"T_710ed_row0_col4\" class=\"data row0 col4\" >0.8350</td>\n",
       "      <td id=\"T_710ed_row0_col5\" class=\"data row0 col5\" >0.7366</td>\n",
       "      <td id=\"T_710ed_row0_col6\" class=\"data row0 col6\" >0.7377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_710ed_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_710ed_row1_col0\" class=\"data row1 col0\" >0.8251</td>\n",
       "      <td id=\"T_710ed_row1_col1\" class=\"data row1 col1\" >0.9422</td>\n",
       "      <td id=\"T_710ed_row1_col2\" class=\"data row1 col2\" >0.8251</td>\n",
       "      <td id=\"T_710ed_row1_col3\" class=\"data row1 col3\" >0.8242</td>\n",
       "      <td id=\"T_710ed_row1_col4\" class=\"data row1 col4\" >0.8234</td>\n",
       "      <td id=\"T_710ed_row1_col5\" class=\"data row1 col5\" >0.7184</td>\n",
       "      <td id=\"T_710ed_row1_col6\" class=\"data row1 col6\" >0.7197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_710ed_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_710ed_row2_col0\" class=\"data row2 col0\" >0.8219</td>\n",
       "      <td id=\"T_710ed_row2_col1\" class=\"data row2 col1\" >0.9390</td>\n",
       "      <td id=\"T_710ed_row2_col2\" class=\"data row2 col2\" >0.8219</td>\n",
       "      <td id=\"T_710ed_row2_col3\" class=\"data row2 col3\" >0.8214</td>\n",
       "      <td id=\"T_710ed_row2_col4\" class=\"data row2 col4\" >0.8201</td>\n",
       "      <td id=\"T_710ed_row2_col5\" class=\"data row2 col5\" >0.7127</td>\n",
       "      <td id=\"T_710ed_row2_col6\" class=\"data row2 col6\" >0.7144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_710ed_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_710ed_row3_col0\" class=\"data row3 col0\" >0.8398</td>\n",
       "      <td id=\"T_710ed_row3_col1\" class=\"data row3 col1\" >0.9491</td>\n",
       "      <td id=\"T_710ed_row3_col2\" class=\"data row3 col2\" >0.8398</td>\n",
       "      <td id=\"T_710ed_row3_col3\" class=\"data row3 col3\" >0.8403</td>\n",
       "      <td id=\"T_710ed_row3_col4\" class=\"data row3 col4\" >0.8388</td>\n",
       "      <td id=\"T_710ed_row3_col5\" class=\"data row3 col5\" >0.7424</td>\n",
       "      <td id=\"T_710ed_row3_col6\" class=\"data row3 col6\" >0.7438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_710ed_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_710ed_row4_col0\" class=\"data row4 col0\" >0.8295</td>\n",
       "      <td id=\"T_710ed_row4_col1\" class=\"data row4 col1\" >0.9434</td>\n",
       "      <td id=\"T_710ed_row4_col2\" class=\"data row4 col2\" >0.8295</td>\n",
       "      <td id=\"T_710ed_row4_col3\" class=\"data row4 col3\" >0.8294</td>\n",
       "      <td id=\"T_710ed_row4_col4\" class=\"data row4 col4\" >0.8283</td>\n",
       "      <td id=\"T_710ed_row4_col5\" class=\"data row4 col5\" >0.7257</td>\n",
       "      <td id=\"T_710ed_row4_col6\" class=\"data row4 col6\" >0.7270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_710ed_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_710ed_row5_col0\" class=\"data row5 col0\" >0.8333</td>\n",
       "      <td id=\"T_710ed_row5_col1\" class=\"data row5 col1\" >0.9408</td>\n",
       "      <td id=\"T_710ed_row5_col2\" class=\"data row5 col2\" >0.8333</td>\n",
       "      <td id=\"T_710ed_row5_col3\" class=\"data row5 col3\" >0.8302</td>\n",
       "      <td id=\"T_710ed_row5_col4\" class=\"data row5 col4\" >0.8297</td>\n",
       "      <td id=\"T_710ed_row5_col5\" class=\"data row5 col5\" >0.7300</td>\n",
       "      <td id=\"T_710ed_row5_col6\" class=\"data row5 col6\" >0.7323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_710ed_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_710ed_row6_col0\" class=\"data row6 col0\" >0.8323</td>\n",
       "      <td id=\"T_710ed_row6_col1\" class=\"data row6 col1\" >0.9433</td>\n",
       "      <td id=\"T_710ed_row6_col2\" class=\"data row6 col2\" >0.8323</td>\n",
       "      <td id=\"T_710ed_row6_col3\" class=\"data row6 col3\" >0.8333</td>\n",
       "      <td id=\"T_710ed_row6_col4\" class=\"data row6 col4\" >0.8315</td>\n",
       "      <td id=\"T_710ed_row6_col5\" class=\"data row6 col5\" >0.7303</td>\n",
       "      <td id=\"T_710ed_row6_col6\" class=\"data row6 col6\" >0.7318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_710ed_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_710ed_row7_col0\" class=\"data row7 col0\" >0.8299</td>\n",
       "      <td id=\"T_710ed_row7_col1\" class=\"data row7 col1\" >0.9427</td>\n",
       "      <td id=\"T_710ed_row7_col2\" class=\"data row7 col2\" >0.8299</td>\n",
       "      <td id=\"T_710ed_row7_col3\" class=\"data row7 col3\" >0.8311</td>\n",
       "      <td id=\"T_710ed_row7_col4\" class=\"data row7 col4\" >0.8290</td>\n",
       "      <td id=\"T_710ed_row7_col5\" class=\"data row7 col5\" >0.7263</td>\n",
       "      <td id=\"T_710ed_row7_col6\" class=\"data row7 col6\" >0.7280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_710ed_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_710ed_row8_col0\" class=\"data row8 col0\" >0.8333</td>\n",
       "      <td id=\"T_710ed_row8_col1\" class=\"data row8 col1\" >0.9431</td>\n",
       "      <td id=\"T_710ed_row8_col2\" class=\"data row8 col2\" >0.8333</td>\n",
       "      <td id=\"T_710ed_row8_col3\" class=\"data row8 col3\" >0.8312</td>\n",
       "      <td id=\"T_710ed_row8_col4\" class=\"data row8 col4\" >0.8311</td>\n",
       "      <td id=\"T_710ed_row8_col5\" class=\"data row8 col5\" >0.7312</td>\n",
       "      <td id=\"T_710ed_row8_col6\" class=\"data row8 col6\" >0.7326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_710ed_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_710ed_row9_col0\" class=\"data row9 col0\" >0.8320</td>\n",
       "      <td id=\"T_710ed_row9_col1\" class=\"data row9 col1\" >0.9454</td>\n",
       "      <td id=\"T_710ed_row9_col2\" class=\"data row9 col2\" >0.8320</td>\n",
       "      <td id=\"T_710ed_row9_col3\" class=\"data row9 col3\" >0.8337</td>\n",
       "      <td id=\"T_710ed_row9_col4\" class=\"data row9 col4\" >0.8314</td>\n",
       "      <td id=\"T_710ed_row9_col5\" class=\"data row9 col5\" >0.7300</td>\n",
       "      <td id=\"T_710ed_row9_col6\" class=\"data row9 col6\" >0.7315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_710ed_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_710ed_row10_col0\" class=\"data row10 col0\" >0.8313</td>\n",
       "      <td id=\"T_710ed_row10_col1\" class=\"data row10 col1\" >0.9436</td>\n",
       "      <td id=\"T_710ed_row10_col2\" class=\"data row10 col2\" >0.8313</td>\n",
       "      <td id=\"T_710ed_row10_col3\" class=\"data row10 col3\" >0.8311</td>\n",
       "      <td id=\"T_710ed_row10_col4\" class=\"data row10 col4\" >0.8298</td>\n",
       "      <td id=\"T_710ed_row10_col5\" class=\"data row10 col5\" >0.7284</td>\n",
       "      <td id=\"T_710ed_row10_col6\" class=\"data row10 col6\" >0.7299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_710ed_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_710ed_row11_col0\" class=\"data row11 col0\" >0.0049</td>\n",
       "      <td id=\"T_710ed_row11_col1\" class=\"data row11 col1\" >0.0027</td>\n",
       "      <td id=\"T_710ed_row11_col2\" class=\"data row11 col2\" >0.0049</td>\n",
       "      <td id=\"T_710ed_row11_col3\" class=\"data row11 col3\" >0.0052</td>\n",
       "      <td id=\"T_710ed_row11_col4\" class=\"data row11 col4\" >0.0050</td>\n",
       "      <td id=\"T_710ed_row11_col5\" class=\"data row11 col5\" >0.0080</td>\n",
       "      <td id=\"T_710ed_row11_col6\" class=\"data row11 col6\" >0.0079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1d6d0a75310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    }
   ],
   "source": [
    "params = {'num_leaves': (10,20),  # Número máximo de hojas por árbol\n",
    "    'learning_rate': (0.1,0.5),  # Tasa de aprendizaje\n",
    "    'feature_fraction': (0.5,0.8),  # Proporción de características a considerar en cada iteración\n",
    "    'bagging_fraction': (0.5,0.8),  # Proporción de datos a considerar en cada iteración\n",
    "    'bagging_freq': (5,6),  # Frecuencia de uso de muestreo\n",
    "}\n",
    "\n",
    "# Perform Bayesian Search\n",
    "tuned_dt = tune_model(dt, custom_grid=params, search_library='scikit-optimize',search_algorithm='bayesian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGBMClassifier(bagging_fraction=0.8, bagging_freq=5, boosting_type='gbdt',\n",
      "               class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,\n",
      "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
      "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
      "               n_estimators=100, n_jobs=-1, num_leaves=20, objective=None,\n",
      "               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,\n",
      "               subsample_for_bin=200000, subsample_freq=0)\n"
     ]
    }
   ],
   "source": [
    "print(tuned_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualización del modelo\n",
    "plot_model(tuned_dt, plot='confusion_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalizar el modelo\n",
    "final_dt = finalize_model(tuned_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id                                                  int64\n",
      "Marital status                                      int64\n",
      "Application mode                                    int64\n",
      "Application order                                   int64\n",
      "Course                                              int64\n",
      "Daytime/evening attendance                          int64\n",
      "Previous qualification                              int64\n",
      "Previous qualification (grade)                    float64\n",
      "Nacionality                                         int64\n",
      "Mother's qualification                              int64\n",
      "Father's qualification                              int64\n",
      "Mother's occupation                                 int64\n",
      "Father's occupation                                 int64\n",
      "Admission grade                                   float64\n",
      "Displaced                                           int64\n",
      "Educational special needs                           int64\n",
      "Debtor                                              int64\n",
      "Tuition fees up to date                             int64\n",
      "Gender                                              int64\n",
      "Scholarship holder                                  int64\n",
      "Age at enrollment                                   int64\n",
      "International                                       int64\n",
      "Curricular units 1st sem (credited)                 int64\n",
      "Curricular units 1st sem (enrolled)                 int64\n",
      "Curricular units 1st sem (evaluations)              int64\n",
      "Curricular units 1st sem (approved)                 int64\n",
      "Curricular units 1st sem (grade)                  float64\n",
      "Curricular units 1st sem (without evaluations)      int64\n",
      "Curricular units 2nd sem (credited)                 int64\n",
      "Curricular units 2nd sem (enrolled)                 int64\n",
      "Curricular units 2nd sem (evaluations)              int64\n",
      "Curricular units 2nd sem (approved)                 int64\n",
      "Curricular units 2nd sem (grade)                  float64\n",
      "Curricular units 2nd sem (without evaluations)      int64\n",
      "Unemployment rate                                 float64\n",
      "Inflation rate                                    float64\n",
      "GDP                                               float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "column_types = df_test.dtypes\n",
    "print(column_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Marital status</th>\n",
       "      <th>Application mode</th>\n",
       "      <th>Application order</th>\n",
       "      <th>Course</th>\n",
       "      <th>Daytime/evening attendance</th>\n",
       "      <th>Previous qualification</th>\n",
       "      <th>Previous qualification (grade)</th>\n",
       "      <th>Nacionality</th>\n",
       "      <th>Mother's qualification</th>\n",
       "      <th>...</th>\n",
       "      <th>Curricular units 2nd sem (enrolled)</th>\n",
       "      <th>Curricular units 2nd sem (evaluations)</th>\n",
       "      <th>Curricular units 2nd sem (approved)</th>\n",
       "      <th>Curricular units 2nd sem (grade)</th>\n",
       "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
       "      <th>Unemployment rate</th>\n",
       "      <th>Inflation rate</th>\n",
       "      <th>GDP</th>\n",
       "      <th>prediction_label</th>\n",
       "      <th>prediction_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76518</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>13.9</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>0.79</td>\n",
       "      <td>Dropout</td>\n",
       "      <td>0.9939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76519</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>11.1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2.02</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.9731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76520</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-4.06</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>0.7408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>76521</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "      <td>9147</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.51</td>\n",
       "      <td>Enrolled</td>\n",
       "      <td>0.4392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>76522</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>9670</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>2</td>\n",
       "      <td>7.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>Enrolled</td>\n",
       "      <td>0.6613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51007</th>\n",
       "      <td>127525</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>128.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-4.06</td>\n",
       "      <td>Dropout</td>\n",
       "      <td>0.8678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51008</th>\n",
       "      <td>127526</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>9119</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>133.100006</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-3.12</td>\n",
       "      <td>Dropout</td>\n",
       "      <td>0.9895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51009</th>\n",
       "      <td>127527</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-4.06</td>\n",
       "      <td>Dropout</td>\n",
       "      <td>0.9773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51010</th>\n",
       "      <td>127528</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9773</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>Dropout</td>\n",
       "      <td>0.9238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51011</th>\n",
       "      <td>127529</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>171</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>Dropout</td>\n",
       "      <td>0.9732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>51012 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  Marital status  Application mode  Application order  Course  \\\n",
       "0       76518               1                 1                  1    9500   \n",
       "1       76519               1                 1                  1    9238   \n",
       "2       76520               1                 1                  1    9238   \n",
       "3       76521               1                44                  1    9147   \n",
       "4       76522               1                39                  1    9670   \n",
       "...       ...             ...               ...                ...     ...   \n",
       "51007  127525               1                 1                  2     171   \n",
       "51008  127526               2                39                  1    9119   \n",
       "51009  127527               1                 1                  1     171   \n",
       "51010  127528               1                 1                  3    9773   \n",
       "51011  127529               1                 1                  1     171   \n",
       "\n",
       "       Daytime/evening attendance  Previous qualification  \\\n",
       "0                               1                       1   \n",
       "1                               1                       1   \n",
       "2                               1                       1   \n",
       "3                               1                      39   \n",
       "4                               1                       1   \n",
       "...                           ...                     ...   \n",
       "51007                           1                       1   \n",
       "51008                           1                      19   \n",
       "51009                           1                       1   \n",
       "51010                           1                       1   \n",
       "51011                           1                       1   \n",
       "\n",
       "       Previous qualification (grade)  Nacionality  Mother's qualification  \\\n",
       "0                          141.000000            1                       3   \n",
       "1                          128.000000            1                       1   \n",
       "2                          118.000000            1                       1   \n",
       "3                          130.000000            1                       1   \n",
       "4                          110.000000            1                       1   \n",
       "...                               ...          ...                     ...   \n",
       "51007                      128.000000            1                      38   \n",
       "51008                      133.100006            1                      19   \n",
       "51009                      127.000000            1                       1   \n",
       "51010                      132.000000            1                      19   \n",
       "51011                      129.000000            1                      37   \n",
       "\n",
       "       ...  Curricular units 2nd sem (enrolled)  \\\n",
       "0      ...                                    8   \n",
       "1      ...                                    6   \n",
       "2      ...                                    6   \n",
       "3      ...                                    8   \n",
       "4      ...                                    6   \n",
       "...    ...                                  ...   \n",
       "51007  ...                                    0   \n",
       "51008  ...                                    5   \n",
       "51009  ...                                    0   \n",
       "51010  ...                                    6   \n",
       "51011  ...                                    0   \n",
       "\n",
       "       Curricular units 2nd sem (evaluations)  \\\n",
       "0                                           0   \n",
       "1                                           6   \n",
       "2                                          11   \n",
       "3                                          14   \n",
       "4                                           9   \n",
       "...                                       ...   \n",
       "51007                                       0   \n",
       "51008                                       5   \n",
       "51009                                       0   \n",
       "51010                                       9   \n",
       "51011                                       0   \n",
       "\n",
       "       Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
       "0                                        0                          0.000000   \n",
       "1                                        6                         13.500000   \n",
       "2                                        5                         11.000000   \n",
       "3                                        5                         11.000000   \n",
       "4                                        4                         10.666667   \n",
       "...                                    ...                               ...   \n",
       "51007                                    0                          0.000000   \n",
       "51008                                    0                          0.000000   \n",
       "51009                                    0                          0.000000   \n",
       "51010                                    3                         13.000000   \n",
       "51011                                    0                          0.000000   \n",
       "\n",
       "       Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
       "0                                                   0               13.9   \n",
       "1                                                   0               11.1   \n",
       "2                                                   0               15.5   \n",
       "3                                                   0                8.9   \n",
       "4                                                   2                7.6   \n",
       "...                                               ...                ...   \n",
       "51007                                               0               15.5   \n",
       "51008                                               0                9.4   \n",
       "51009                                               0               15.5   \n",
       "51010                                               0                7.6   \n",
       "51011                                               0                7.6   \n",
       "\n",
       "       Inflation rate   GDP  prediction_label  prediction_score  \n",
       "0                -0.3  0.79           Dropout            0.9939  \n",
       "1                 0.6  2.02          Graduate            0.9731  \n",
       "2                 2.8 -4.06          Graduate            0.7408  \n",
       "3                 1.4  3.51          Enrolled            0.4392  \n",
       "4                 2.6  0.32          Enrolled            0.6613  \n",
       "...               ...   ...               ...               ...  \n",
       "51007             2.8 -4.06           Dropout            0.8678  \n",
       "51008            -0.8 -3.12           Dropout            0.9895  \n",
       "51009             2.8 -4.06           Dropout            0.9773  \n",
       "51010             2.6  0.32           Dropout            0.9238  \n",
       "51011             2.6  0.32           Dropout            0.9732  \n",
       "\n",
       "[51012 rows x 39 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Realizar predicciones\n",
    "predictions = predict_model(final_dt, data=df_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\n",
    "    'id': df_test['id'],\n",
    "    'Target': predictions['prediction_score']\n",
    "})\n",
    "\n",
    "# Save the result to a CSV file\n",
    "result.to_csv('predictions_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformation Pipeline and Model Successfully Saved\n",
      "Transformation Pipeline and Model Successfully Loaded\n"
     ]
    }
   ],
   "source": [
    "# Guardar y cargar modelos\n",
    "save_model(final_dt, 'final_dt_')\n",
    "\n",
    "# To load the model later\n",
    "loaded_model = load_model('final_dt_')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
